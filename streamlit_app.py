import streamlit as st
import os
import tempfile
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables import RunnablePassthrough
from langchain.schema import Document
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_core.messages import HumanMessage, AIMessage
import docx2txt
import PyPDF2
import io
import time
import json

# é¡µé¢é…ç½® - ä¼˜åŒ–å¸ƒå±€
st.set_page_config(
    page_title="é‡åº†ç§‘æŠ€å¤§å­¦æ™ºèƒ½é—®ç­”ç³»ç»Ÿ", 
    page_icon="ğŸŒ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ä¼˜åŒ–çš„CSSæ ·å¼ - ç¡®ä¿å•é¡µæ˜¾ç¤º
st.markdown("""
<style>
    /* é‡ç½®é»˜è®¤æ ·å¼ï¼Œç¡®ä¿å•é¡µæ˜¾ç¤º */
    .main .block-container {
        padding-top: 1rem;
        padding-bottom: 1rem;
        max-width: 100%;
        overflow: hidden;
    }
    
    /* ç´§å‡‘çš„æ ‡é¢˜æ ·å¼ */
    .custom-title {
        font-size: 28px;
        font-weight: 700;
        text-align: center;
        padding: 0.8rem;
        color: white;
        background: linear-gradient(to right, #667eea, #764ba2);
        border-radius: 8px;
        margin-bottom: 1rem;
        box-shadow: 0 2px 8px rgba(0,0,0,0.1);
    }
    
    /* ä¼˜åŒ–èŠå¤©å®¹å™¨ */
    .chat-container {
        height: 60vh;
        overflow-y: auto;
        border: 1px solid #e0e0e0;
        border-radius: 8px;
        padding: 0.5rem;
        background: #fafafa;
    }
    
    /* ä¼˜åŒ–æ¶ˆæ¯æ°”æ³¡ */
    .message-bubble {
        background-color: #f0f2f6;
        padding: 0.8rem;
        border-radius: 10px;
        margin: 0.3rem 0;
        box-shadow: 0 1px 2px rgba(0,0,0,0.05);
        line-height: 1.4;
    }
    
    .assistant-bubble {
        background-color: #e6f0ff;
    }
    
    /* ç´§å‡‘çš„æŒ‰é’®æ ·å¼ */
    .action-buttons {
        display: flex;
        gap: 8px;
        margin-top: 0.5rem;
        align-items: center;
    }
    
    .copy-button {
        background: white;
        border: 1px solid #ddd;
        border-radius: 4px;
        padding: 4px 8px;
        cursor: pointer;
        font-size: 14px;
        color: #666;
        transition: all 0.2s ease;
        min-width: 60px;
        height: 28px;
        display: flex;
        align-items: center;
        justify-content: center;
    }
    
    .copy-button:hover {
        background: #f8f9fa;
        border-color: #adb5bd;
        color: #333;
    }
    
    /* ä¾§è¾¹æ ä¼˜åŒ– */
    .sidebar .stSelectbox {
        margin-bottom: 0.5rem;
    }
    
    /* è¾“å…¥æ¡†æ ·å¼ */
    .stChatInput {
        margin-top: 0.5rem;
    }
    
    /* éšè—ä¸å¿…è¦çš„ç©ºç™½ */
    .element-container {
        margin-bottom: 0.5rem;
    }
    
    /* ä¼˜åŒ–åˆ†éš”çº¿ */
    hr {
        margin: 0.5rem 0;
        border: 0;
        height: 1px;
        background: #e0e0e0;
    }
    
    /* ç¡®ä¿å†…å®¹ä¸ä¼šè¢«é®æŒ¡ */
    .main {
        overflow: visible;
    }
    
    /* ç´§å‡‘çš„æŒ‡æ ‡æ˜¾ç¤º */
    .metric-container {
        padding: 0.3rem;
    }
</style>
""", unsafe_allow_html=True)

# ---------- åˆå§‹åŒ–ä¼šè¯çŠ¶æ€ ----------
def initialize_session_state():
    """åˆå§‹åŒ–ä¼šè¯çŠ¶æ€å˜é‡"""
    if "messages" not in st.session_state:
        st.session_state.messages = []
        
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []
        
    if "regenerate_question" not in st.session_state:
        st.session_state.regenerate_question = None
        
    if "regenerate_index" not in st.session_state:
        st.session_state.regenerate_index = None

# ---------- åˆ›å»ºç´§å‡‘çš„å¤åˆ¶æŒ‰é’® ----------
def create_compact_copy_button(message_index, message_text):
    """åˆ›å»ºç´§å‡‘çš„å¤åˆ¶æŒ‰é’®"""
    escaped_text = message_text.replace('\\', '\\\\').replace('`', '\\`').replace("'", "\\'").replace('"', '\\"').replace('\n', '\\n').replace('\r', '\\r')

    copy_html = f'''
    <div style="display: flex; align-items: center; gap: 8px; margin: 3px 0;">
        <button onclick="copyText{message_index}()" class="copy-button" 
                style="background: white; border: 1px solid #ddd; border-radius: 4px; padding: 4px 8px; cursor: pointer; font-size: 12px; color: #666; min-width: 50px; height: 24px;">
            ğŸ“‹ å¤åˆ¶
        </button>
        <span id="status-{message_index}" style="color: #28a745; font-size: 11px;"></span>
    </div>

    <script>
    function copyText{message_index}() {{
        const text = `{escaped_text}`;
        const status = document.getElementById('status-{message_index}');
        
        if (navigator.clipboard) {{
            navigator.clipboard.writeText(text).then(() => {{
                status.textContent = 'âœ… å·²å¤åˆ¶';
                setTimeout(() => status.textContent = '', 2000);
            }});
        }} else {{
            const textarea = document.createElement('textarea');
            textarea.value = text;
            document.body.appendChild(textarea);
            textarea.select();
            document.execCommand('copy');
            document.body.removeChild(textarea);
            status.textContent = 'âœ… å·²å¤åˆ¶';
            setTimeout(() => status.textContent = '', 2000);
        }}
    }}
    </script>
    '''
    return copy_html

# ---------- å¤„ç†é‡æ–°ç”Ÿæˆè¯·æ±‚ ----------
def handle_regenerate_request():
    """å¤„ç†é‡æ–°ç”Ÿæˆå›ç­”çš„è¯·æ±‚"""
    if st.session_state.regenerate_question is not None and st.session_state.regenerate_index is not None:
        question = st.session_state.regenerate_question
        message_index = st.session_state.regenerate_index
                
        try:
            if message_index > 0 and message_index < len(st.session_state.messages):
                st.session_state.messages = st.session_state.messages[:message_index]
                pairs_to_keep = message_index // 2
                st.session_state.chat_history = st.session_state.chat_history[:pairs_to_keep * 2]
                                
                if not st.session_state.messages or st.session_state.messages[-1][0] != "user":
                    st.session_state.messages.append(("user", question))
                    st.session_state.chat_history.append(HumanMessage(content=question))
                                
                st.session_state.regenerate_question = None
                st.session_state.regenerate_index = None
                return question
                        
        except Exception as e:
            st.error(f"å¤„ç†é‡æ–°ç”Ÿæˆè¯·æ±‚æ—¶å‡ºé”™: {e}")
            st.session_state.regenerate_question = None
            st.session_state.regenerate_index = None
        
    return None

# ---------- ä»æœ¬åœ° Markdown æ–‡ä»¶è·å–æ–‡æ¡£å†…å®¹ ----------
def fetch_document_from_file(file_path):
    try:
        with open(file_path, "r", encoding="utf-8") as file:
            return file.read()
    except FileNotFoundError:
        return ""
    except Exception as e:
        st.error(f"æ— æ³•è¯»å–æ–‡ä»¶: {e}")
        return ""

# ---------- å¤„ç†ä¸Šä¼ æ–‡ä»¶ ----------
def process_uploaded_file(uploaded_file):
    """å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶å¹¶æå–æ–‡æœ¬å†…å®¹"""
    try:
        file_extension = uploaded_file.name.split('.')[-1].lower()
                
        if file_extension == 'txt':
            content = str(uploaded_file.read(), "utf-8")
        elif file_extension == 'md':
            content = str(uploaded_file.read(), "utf-8")
        elif file_extension == 'pdf':
            pdf_reader = PyPDF2.PdfReader(io.BytesIO(uploaded_file.read()))
            content = ""
            for page_num, page in enumerate(pdf_reader.pages):
                page_text = page.extract_text()
                content += f"\n[ç¬¬{page_num+1}é¡µ]\n{page_text}"
        elif file_extension in ['docx', 'doc']:
            with tempfile.NamedTemporaryFile(delete=False, suffix=f'.{file_extension}') as tmp_file:
                tmp_file.write(uploaded_file.read())
                tmp_file_path = tmp_file.name
                        
            content = docx2txt.process(tmp_file_path)
            os.unlink(tmp_file_path)
        else:
            st.error(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_extension}")
            return ""
                
        if not content or len(content.strip()) == 0:
            st.error(f"æ–‡ä»¶ {uploaded_file.name} å†…å®¹ä¸ºç©º")
            return ""
                
        return content
            
    except Exception as e:
        st.error(f"å¤„ç†æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
        return ""

# ---------- æ„å»ºæ£€ç´¢å™¨ ----------
def build_retriever():
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        st.error("è¯·å…ˆè®¾ç½®ç¯å¢ƒå˜é‡ OPENAI_API_KEY")
        st.stop()
        
    all_docs = []
        
    # ä»æœ¬åœ°æ–‡ä»¶è·å–æ–‡æ¡£å†…å®¹
    DOCUMENT_FILE_PATH = "æµ‹è¯•.md"
    if os.path.exists(DOCUMENT_FILE_PATH):
        raw_docs = fetch_document_from_file(DOCUMENT_FILE_PATH)
        if raw_docs:
            all_docs.append(raw_docs)
        
    # æ·»åŠ ä¸Šä¼ çš„æ–‡æ¡£å†…å®¹
    if 'uploaded_docs' in st.session_state and st.session_state.uploaded_docs:
        all_docs.extend(st.session_state.uploaded_docs)
        
    if not all_docs:
        return None
        
    # åˆ‡åˆ†é•¿æ–‡æ¡£
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
    docs = text_splitter.create_documents(all_docs)
        
    embeddings = OpenAIEmbeddings(openai_api_key=api_key)
    vectorstore = FAISS.from_documents(docs, embeddings)
    return vectorstore.as_retriever(search_kwargs={"k": 4})

# ---------- æ„å»ºé—®ç­”é“¾ ----------
def get_qa_chain_with_memory():
    llm = ChatOpenAI(model_name="gpt-4o", temperature=0, openai_api_key=os.getenv("OPENAI_API_KEY"))
        
    system = (
        "ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„ AI åŠ©æ‰‹ã€‚\n"
        "è¯·é¦–å…ˆåŸºäºä¸‹é¢æä¾›çš„ä¸Šä¸‹æ–‡ä¿¡æ¯å›ç­”é—®é¢˜ã€‚å¦‚æœä¸Šä¸‹æ–‡ä¸­åŒ…å«ç›¸å…³ä¿¡æ¯ï¼Œè¯·ä¼˜å…ˆä½¿ç”¨è¿™äº›ä¿¡æ¯ã€‚"
        "å¦‚æœä¸Šä¸‹æ–‡ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·ä½¿ç”¨ä½ çš„çŸ¥è¯†å’Œç»éªŒæ¥å›ç­”é—®é¢˜ï¼Œå¹¶åœ¨å›ç­”å¼€å¤´è¯´æ˜'åŸºäºæˆ‘çš„ä¸€èˆ¬çŸ¥è¯†'ã€‚\n"
        "è¯·ä¿æŒå›ç­”çš„å‡†ç¡®æ€§å’Œæœ‰ç”¨æ€§ã€‚\n\n"
        "ä¸Šä¸‹æ–‡ä¿¡æ¯:\n{context}\n\n"
        "è¯·ç»“åˆå¯¹è¯å†å²å’Œä¸Šä¸‹æ–‡ä¿¡æ¯æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚"
    )
        
    prompt = ChatPromptTemplate.from_messages([
        ("system", system),
        MessagesPlaceholder(variable_name="chat_history"),
        ("human", "{question}")
    ])
        
    def format_docs(docs):
        if not docs:
            return "æ²¡æœ‰æ‰¾åˆ°ç›¸å…³çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚"
        return "\n\n".join(d.page_content for d in docs)
        
    def get_context_and_question(inputs):
        retriever = build_retriever()
        if retriever:
            try:
                context_docs = retriever.invoke(inputs["question"])
                context = format_docs(context_docs)
            except Exception as e:
                context = "æ£€ç´¢å‡ºé”™ï¼Œæ²¡æœ‰æ‰¾åˆ°ç›¸å…³çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚"
        else:
            context = "æ²¡æœ‰æ‰¾åˆ°ç›¸å…³çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚"
                
        return {
            "context": context,
            "question": inputs["question"],
            "chat_history": inputs["chat_history"]
        }
        
    chain = (
        get_context_and_question
        | prompt
        | llm
        | StrOutputParser()
    )
        
    return chain

# ---------- ç´§å‡‘çš„ä¾§è¾¹æ  ----------
def setup_compact_sidebar():
    with st.sidebar:
        st.markdown("### ğŸ“ æ–‡ä»¶ä¸Šä¼ ")
                
        uploaded_files = st.file_uploader(
            "ä¸Šä¼ æ–‡æ¡£",
            type=['txt', 'md', 'pdf', 'docx', 'doc'],
            accept_multiple_files=True
        )
                
        if uploaded_files:
            if 'uploaded_docs' not in st.session_state:
                st.session_state.uploaded_docs = []
            if 'uploaded_files_info' not in st.session_state:
                st.session_state.uploaded_files_info = []
                        
            existing_files = [info['name'] for info in st.session_state.uploaded_files_info]
            new_files_processed = 0
                        
            for uploaded_file in uploaded_files:
                if uploaded_file.name not in existing_files:
                    content = process_uploaded_file(uploaded_file)
                    if content:
                        st.session_state.uploaded_docs.append(content)
                        st.session_state.uploaded_files_info.append({
                            'name': uploaded_file.name,
                            'size': uploaded_file.size,
                            'content_length': len(content)
                        })
                        new_files_processed += 1
                        
            if new_files_processed > 0:
                st.session_state.chain = get_qa_chain_with_memory()
                st.success(f"âœ… å¤„ç†äº† {new_files_processed} ä¸ªæ–‡ä»¶")
                st.rerun()
                
        # ç´§å‡‘çš„æ–‡ä»¶åˆ—è¡¨æ˜¾ç¤º
        if 'uploaded_files_info' in st.session_state and st.session_state.uploaded_files_info:
            st.markdown("### ğŸ“‹ å·²ä¸Šä¼ æ–‡ä»¶")
            for file_info in st.session_state.uploaded_files_info:
                st.text(f"ğŸ“„ {file_info['name'][:20]}...")
                
        # çŸ¥è¯†åº“çŠ¶æ€
        if 'uploaded_docs' in st.session_state:
            total_chars = sum(len(doc) for doc in st.session_state.uploaded_docs)
            st.markdown("### ğŸ“Š çŸ¥è¯†åº“çŠ¶æ€")
            col1, col2 = st.columns(2)
            with col1:
                st.metric("æ–‡æ¡£", len(st.session_state.uploaded_docs))
            with col2:
                st.metric("å­—ç¬¦", f"{total_chars//1000}K")
                
        st.markdown("---")
                
        # æ“ä½œæŒ‰é’®
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸ—‘ï¸ æ¸…é™¤å¯¹è¯", use_container_width=True):
                st.session_state.messages = []
                st.session_state.chat_history = []
                st.rerun()
        
        with col2:
            if st.button("ğŸ“ æ¸…é™¤æ–‡ä»¶", use_container_width=True):
                if 'uploaded_docs' in st.session_state:
                    del st.session_state.uploaded_docs
                if 'uploaded_files_info' in st.session_state:
                    del st.session_state.uploaded_files_info
                st.rerun()

# ---------- ç”ŸæˆAIå›ç­” ----------
def generate_ai_response(prompt, container):
    """ç”ŸæˆAIå›ç­”"""
    try:
        chain_input = {
            "question": prompt,
            "chat_history": st.session_state.chat_history
        }
                
        with st.spinner("æ€è€ƒä¸­..."):
            response = st.write_stream(st.session_state.chain.stream(chain_input))
                
        st.session_state.messages.append(("assistant", response))
                
        st.session_state.chat_history.extend([
            HumanMessage(content=prompt),
            AIMessage(content=response)
        ])
                
        if len(st.session_state.chat_history) > 20:
            st.session_state.chat_history = st.session_state.chat_history[-20:]
                
        # æ·»åŠ æ“ä½œæŒ‰é’®
        message_index = len(st.session_state.messages) - 1
        
        col1, col2, col3 = st.columns([2, 2, 6])
        
        with col1:
            copy_html = create_compact_copy_button(message_index, response)
            st.components.v1.html(copy_html, height=35)
                
        with col2:
            if st.button("ğŸ”„ é‡æ–°ç”Ÿæˆ", key=f"regen_{message_index}"):
                st.session_state.regenerate_question = prompt
                st.session_state.regenerate_index = message_index
                st.rerun()
                    
    except Exception as e:
        st.error(f"ç”Ÿæˆå›ç­”æ—¶å‡ºé”™: {str(e)}")

# ---------- ä¸»å‡½æ•° ----------
def main():
    # åˆå§‹åŒ–
    initialize_session_state()
    
    # ç´§å‡‘çš„æ ‡é¢˜
    st.markdown('<div class="custom-title">ğŸŒ é‡åº†ç§‘æŠ€å¤§å­¦ Â· æ™ºèƒ½é—®ç­”ç³»ç»Ÿ</div>', unsafe_allow_html=True)

    # è®¾ç½®ä¾§è¾¹æ 
    setup_compact_sidebar()

    # åˆå§‹åŒ–é—®ç­”é“¾
    if "chain" not in st.session_state:
        st.session_state.chain = get_qa_chain_with_memory()

    # å¤„ç†é‡æ–°ç”Ÿæˆè¯·æ±‚
    regenerate_question = handle_regenerate_request()

    # èŠå¤©åŒºåŸŸ - ä½¿ç”¨å›ºå®šé«˜åº¦å®¹å™¨
    st.markdown("### ğŸ’¬ æ™ºèƒ½é—®ç­”")
    
    # åˆ›å»ºèŠå¤©å®¹å™¨ï¼Œè®¾ç½®åˆé€‚çš„é«˜åº¦
    chat_container = st.container(height=400)

    # æ˜¾ç¤ºèŠå¤©å†å²
    with chat_container:
        for i, (role, text) in enumerate(st.session_state.messages):
            avatar = "ğŸ§‘â€ğŸ’»" if role == "user" else "ğŸš€"
            
            with st.chat_message(role, avatar=avatar):
                # ä½¿ç”¨ç´§å‡‘çš„æ ·å¼æ˜¾ç¤ºæ¶ˆæ¯
                bubble_class = "message-bubble" + (" assistant-bubble" if role == "assistant" else "")
                st.markdown(f'<div class="{bubble_class}">{text}</div>', unsafe_allow_html=True)

                # ä¸ºåŠ©æ‰‹æ¶ˆæ¯æ·»åŠ æ“ä½œæŒ‰é’®
                if role == "assistant":
                    question = st.session_state.messages[i-1][1] if i > 0 and st.session_state.messages[i-1][0] == "user" else None
                    
                    col1, col2, _ = st.columns([2, 2, 6])
                    with col1:
                        copy_html = create_compact_copy_button(i, text)
                        st.components.v1.html(copy_html, height=30)
                    with col2:
                        if question and st.button("ğŸ”„", key=f"regen_history_{i}", help="é‡æ–°ç”Ÿæˆ"):
                            st.session_state.regenerate_question = question
                            st.session_state.regenerate_index = i
                            st.rerun()

    # å¤„ç†é‡æ–°ç”Ÿæˆ
    if regenerate_question:
        with chat_container:
            with st.chat_message("assistant", avatar="ğŸš€"):
                generate_ai_response(regenerate_question, chat_container)
        st.rerun()

    # ç”¨æˆ·è¾“å…¥
    if prompt := st.chat_input("è¯·è¾“å…¥ä½ çš„é—®é¢˜..."):
        st.session_state.messages.append(("user", prompt))
        
        with chat_container:
            with st.chat_message("user", avatar="ğŸ§‘â€ğŸ’»"):
                st.markdown(f'<div class="message-bubble">{prompt}</div>', unsafe_allow_html=True)
            
            with st.chat_message("assistant", avatar="ğŸš€"):
                generate_ai_response(prompt, chat_container)

if __name__ == "__main__":
    main()
