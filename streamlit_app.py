import streamlit as st
import os
import tempfile
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables import RunnablePassthrough
from langchain.schema import Document
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_core.messages import HumanMessage, AIMessage
import docx2txt
import PyPDF2
import io

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="åŠ¨æ‰‹å­¦å¤§æ¨¡å‹åº”ç”¨å¼€å‘", 
    page_icon="ğŸ¦œğŸ”—",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
<style>
    .main-header {
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        padding: 1rem;
        border-radius: 10px;
        margin-bottom: 2rem;
    }
    .main-header h1 {
        color: white;
        text-align: center;
        margin: 0;
    }
    .upload-section {
        border: 2px dashed #667eea;
        border-radius: 10px;
        padding: 1rem;
        margin: 1rem 0;
    }
    .chat-container {
        border-radius: 10px;
        border: 1px solid #e0e0e0;
        padding: 1rem;
    }
    .sidebar-info {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 10px;
        margin-bottom: 1rem;
    }
</style>
""", unsafe_allow_html=True)

# ---------- 1. ä»æœ¬åœ° Markdown æ–‡ä»¶è·å–æ–‡æ¡£å†…å®¹ ----------
def fetch_document_from_file(file_path):
    try:
        with open(file_path, "r", encoding="utf-8") as file:
            return file.read()
    except FileNotFoundError:
        st.error(f"æ–‡ä»¶æœªæ‰¾åˆ°: {file_path}")
        return ""
    except Exception as e:
        st.error(f"æ— æ³•è¯»å–æ–‡ä»¶: {e}")
        return ""

# ---------- 2. å¤„ç†ä¸Šä¼ æ–‡ä»¶ ----------
def process_uploaded_file(uploaded_file):
    """å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶å¹¶æå–æ–‡æœ¬å†…å®¹"""
    try:
        file_extension = uploaded_file.name.split('.')[-1].lower()
        
        if file_extension == 'txt':
            return str(uploaded_file.read(), "utf-8")
        elif file_extension == 'md':
            return str(uploaded_file.read(), "utf-8")
        elif file_extension == 'pdf':
            pdf_reader = PyPDF2.PdfReader(io.BytesIO(uploaded_file.read()))
            text = ""
            for page in pdf_reader.pages:
                text += page.extract_text()
            return text
        elif file_extension in ['docx', 'doc']:
            # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
            with tempfile.NamedTemporaryFile(delete=False, suffix=f'.{file_extension}') as tmp_file:
                tmp_file.write(uploaded_file.read())
                tmp_file_path = tmp_file.name
            
            text = docx2txt.process(tmp_file_path)
            os.unlink(tmp_file_path)  # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
            return text
        else:
            st.error(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_extension}")
            return ""
    except Exception as e:
        st.error(f"å¤„ç†æ–‡ä»¶æ—¶å‡ºé”™: {e}")
        return ""

# ---------- 3. æ„å»ºæ£€ç´¢å™¨ ----------
def build_retriever(additional_docs=None):
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        st.error("è¯·å…ˆè®¾ç½®ç¯å¢ƒå˜é‡ OPENAI_API_KEY")
        st.stop()
    
    all_docs = []
    
    # ä»æœ¬åœ°æ–‡ä»¶è·å–æ–‡æ¡£å†…å®¹
    DOCUMENT_FILE_PATH = "æµ‹è¯•.md"
    if os.path.exists(DOCUMENT_FILE_PATH):
        raw_docs = fetch_document_from_file(DOCUMENT_FILE_PATH)
        if raw_docs:
            all_docs.append(raw_docs)
    
    # æ·»åŠ ä¸Šä¼ çš„æ–‡æ¡£å†…å®¹
    if additional_docs:
        all_docs.extend(additional_docs)
    
    if not all_docs:
        st.warning("æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ–‡æ¡£å†…å®¹")
        return None
    
    # åˆ‡åˆ†é•¿æ–‡æ¡£
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
    docs = text_splitter.create_documents(all_docs)
    
    embeddings = OpenAIEmbeddings(openai_api_key=api_key)
    vectorstore = FAISS.from_documents(docs, embeddings)
    return vectorstore.as_retriever()

# ---------- 4. æ„å»ºé—®ç­”é“¾ï¼ˆå¸¦è®°å¿†åŠŸèƒ½ï¼‰ ----------
def get_qa_chain_with_memory():
    retriever = build_retriever(st.session_state.get('uploaded_docs', []))
    llm = ChatOpenAI(model_name="gpt-4o", temperature=0, openai_api_key=os.getenv("OPENAI_API_KEY"))
    
    # æ”¹è¿›çš„ç³»ç»Ÿæç¤ºï¼Œå…è®¸æ¨¡å‹åœ¨æ‰¾ä¸åˆ°ç›¸å…³ä¿¡æ¯æ—¶ä½¿ç”¨è‡ªèº«çŸ¥è¯†
    system = (
        "ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„ AI åŠ©æ‰‹ã€‚\n"
        "è¯·é¦–å…ˆåŸºäºä¸‹é¢æä¾›çš„ä¸Šä¸‹æ–‡ä¿¡æ¯å›ç­”é—®é¢˜ã€‚å¦‚æœä¸Šä¸‹æ–‡ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œ"
        "è¯·ä½¿ç”¨ä½ çš„çŸ¥è¯†å’Œç»éªŒæ¥å›ç­”é—®é¢˜ï¼Œå¹¶åœ¨å›ç­”å¼€å¤´è¯´æ˜è¿™æ˜¯åŸºäºä½ çš„ä¸€èˆ¬çŸ¥è¯†ã€‚\n"
        "è¯·ä¿æŒå›ç­”çš„å‡†ç¡®æ€§å’Œæœ‰ç”¨æ€§ã€‚\n\n"
        "ä¸Šä¸‹æ–‡ä¿¡æ¯:\n{context}\n\n"
        "è¯·ç»“åˆå¯¹è¯å†å²å’Œä¸Šä¸‹æ–‡ä¿¡æ¯æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚"
    )
    
    prompt = ChatPromptTemplate.from_messages([
        ("system", system),
        MessagesPlaceholder(variable_name="chat_history"),
        ("human", "{question}")
    ])
    
    def format_docs(docs):
        if not docs:
            return "æ²¡æœ‰æ‰¾åˆ°ç›¸å…³çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚"
        return "\n\n".join(d.page_content for d in docs)
    
    def get_context_and_question(inputs):
        if retriever:
            context = retriever.invoke(inputs["question"])
            return {
                "context": format_docs(context),
                "question": inputs["question"],
                "chat_history": inputs["chat_history"]
            }
        else:
            return {
                "context": "æ²¡æœ‰æ‰¾åˆ°ç›¸å…³çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚",
                "question": inputs["question"],
                "chat_history": inputs["chat_history"]
            }
    
    chain = (
        get_context_and_question
        | prompt
        | llm
        | StrOutputParser()
    )
    
    return chain

# ---------- 5. ä¾§è¾¹æ åŠŸèƒ½ ----------
def setup_sidebar():
    with st.sidebar:
        st.markdown("### ğŸ“ æ–‡ä»¶ä¸Šä¼ ")
        
        # æ–‡ä»¶ä¸Šä¼ å™¨
        uploaded_files = st.file_uploader(
            "ä¸Šä¼ æ–‡æ¡£æ–‡ä»¶",
            type=['txt', 'md', 'pdf', 'docx', 'doc'],
            accept_multiple_files=True,
            help="æ”¯æŒçš„æ ¼å¼ï¼šTXT, MD, PDF, DOCX, DOC"
        )
        
        if uploaded_files:
            if 'uploaded_docs' not in st.session_state:
                st.session_state.uploaded_docs = []
            
            new_docs = []
            for uploaded_file in uploaded_files:
                if uploaded_file.name not in [doc['name'] for doc in st.session_state.get('uploaded_files_info', [])]:
                    content = process_uploaded_file(uploaded_file)
                    if content:
                        new_docs.append(content)
                        
                        # ä¿å­˜æ–‡ä»¶ä¿¡æ¯
                        if 'uploaded_files_info' not in st.session_state:
                            st.session_state.uploaded_files_info = []
                        st.session_state.uploaded_files_info.append({
                            'name': uploaded_file.name,
                            'size': uploaded_file.size
                        })
            
            if new_docs:
                st.session_state.uploaded_docs.extend(new_docs)
                # é‡æ–°æ„å»ºchain
                st.session_state.chain = get_qa_chain_with_memory()
                st.success(f"æˆåŠŸä¸Šä¼  {len(new_docs)} ä¸ªæ–‡ä»¶ï¼")
        
        # æ˜¾ç¤ºå·²ä¸Šä¼ çš„æ–‡ä»¶
        if 'uploaded_files_info' in st.session_state and st.session_state.uploaded_files_info:
            st.markdown("### ğŸ“‹ å·²ä¸Šä¼ æ–‡ä»¶")
            for file_info in st.session_state.uploaded_files_info:
                st.text(f"ğŸ“„ {file_info['name']}")
                st.text(f"   å¤§å°: {file_info['size']} bytes")
        
        st.markdown("---")
        
        # æ¸…é™¤å¯¹è¯å†å²æŒ‰é’®
        if st.button("ğŸ—‘ï¸ æ¸…é™¤å¯¹è¯å†å²", use_container_width=True):
            st.session_state.messages = []
            st.session_state.chat_history = []
            st.rerun()
        
        # æ¸…é™¤ä¸Šä¼ æ–‡ä»¶æŒ‰é’®
        if st.button("ğŸ“ æ¸…é™¤ä¸Šä¼ æ–‡ä»¶", use_container_width=True):
            if 'uploaded_docs' in st.session_state:
                del st.session_state.uploaded_docs
            if 'uploaded_files_info' in st.session_state:
                del st.session_state.uploaded_files_info
            st.session_state.chain = get_qa_chain_with_memory()
            st.success("å·²æ¸…é™¤æ‰€æœ‰ä¸Šä¼ æ–‡ä»¶ï¼")
            st.rerun()
        
        st.markdown("---")
        
        # ä½¿ç”¨è¯´æ˜
        with st.expander("ğŸ“– ä½¿ç”¨è¯´æ˜"):
            st.markdown("""
            **åŠŸèƒ½ç‰¹ç‚¹ï¼š**
            - ğŸ” æ™ºèƒ½æ£€ç´¢ï¼šä»çŸ¥è¯†åº“ä¸­æŸ¥æ‰¾ç›¸å…³ä¿¡æ¯
            - ğŸ§  çŸ¥è¯†èåˆï¼šæ‰¾ä¸åˆ°æ—¶ä½¿ç”¨AIè‡ªèº«çŸ¥è¯†å›ç­”
            - ğŸ’­ å¯¹è¯è®°å¿†ï¼šè®°ä½ä¹‹å‰çš„å¯¹è¯å†…å®¹
            - ğŸ“ æ–‡ä»¶ä¸Šä¼ ï¼šæ”¯æŒå¤šç§æ ¼å¼æ–‡æ¡£
            
            **ä½¿ç”¨æ–¹æ³•ï¼š**
            1. ä¸Šä¼ ç›¸å…³æ–‡æ¡£æ–‡ä»¶
            2. åœ¨ä¸‹æ–¹è¾“å…¥æ¡†ä¸­æé—®
            3. AIä¼šç»“åˆæ–‡æ¡£å’Œå¯¹è¯å†å²å›ç­”
            """)

# ---------- 6. Streamlit ä¸»ç•Œé¢ ----------
def main():
    # é¡µé¢æ ‡é¢˜
    st.markdown("""
    <div class="main-header">
        <h1>ğŸ¦œğŸ”— åŠ¨æ‰‹å­¦å¤§æ¨¡å‹åº”ç”¨å¼€å‘ - å¢å¼ºç‰ˆ</h1>
    </div>
    """, unsafe_allow_html=True)
    
    # è®¾ç½®ä¾§è¾¹æ 
    setup_sidebar()
    
    # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
    if "messages" not in st.session_state:
        st.session_state.messages = []
    
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []
    
    if "chain" not in st.session_state:
        st.session_state.chain = get_qa_chain_with_memory()
    
    # ä¸»èŠå¤©åŒºåŸŸ
    st.markdown("### ğŸ’¬ æ™ºèƒ½é—®ç­”")
    
    # èŠå¤©æ¶ˆæ¯å®¹å™¨
    msgs = st.container(height=500)
    
    # æ˜¾ç¤ºèŠå¤©å†å²
    for role, text in st.session_state.messages:
        with msgs.chat_message(role):
            st.write(text)
    
    # ç”¨æˆ·è¾“å…¥
    if prompt := st.chat_input("è¯·è¾“å…¥ä½ çš„é—®é¢˜..."):
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        st.session_state.messages.append(("user", prompt))
        with msgs.chat_message("user"):
            st.write(prompt)
        
        # ç”ŸæˆAIå›ç­”
        with msgs.chat_message("assistant"):
            try:
                # å‡†å¤‡è¾“å…¥æ•°æ®ï¼ŒåŒ…å«å¯¹è¯å†å²
                chain_input = {
                    "question": prompt,
                    "chat_history": st.session_state.chat_history
                }
                
                # æµå¼è¾“å‡ºå›ç­”
                response = st.write_stream(st.session_state.chain.stream(chain_input))
                
                # ä¿å­˜æ¶ˆæ¯åˆ°å†å²è®°å½•
                st.session_state.messages.append(("assistant", response))
                
                # æ›´æ–°å¯¹è¯å†å²ï¼ˆç”¨äºè®°å¿†åŠŸèƒ½ï¼‰
                st.session_state.chat_history.extend([
                    HumanMessage(content=prompt),
                    AIMessage(content=response)
                ])
                
                # é™åˆ¶å¯¹è¯å†å²é•¿åº¦ï¼Œé¿å…tokenè¿‡å¤š
                if len(st.session_state.chat_history) > 20:
                    st.session_state.chat_history = st.session_state.chat_history[-20:]
                    
            except Exception as e:
                st.error(f"ç”Ÿæˆå›ç­”æ—¶å‡ºé”™: {e}")
                st.session_state.messages.append(("assistant", "æŠ±æ­‰ï¼Œç”Ÿæˆå›ç­”æ—¶å‡ºç°äº†é”™è¯¯ã€‚"))
    
    # åº•éƒ¨ä¿¡æ¯
    st.markdown("---")
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("å¯¹è¯è½®æ•°", len(st.session_state.messages) // 2)
    with col2:
        uploaded_count = len(st.session_state.get('uploaded_files_info', []))
        st.metric("å·²ä¸Šä¼ æ–‡ä»¶", uploaded_count)
    with col3:
        memory_count = len(st.session_state.chat_history) // 2
        st.metric("è®°å¿†å¯¹è¯æ•°", memory_count)

if __name__ == "__main__":
    main()
