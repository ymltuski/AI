import streamlit as st
import os
import requests
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain.schema import Document
from langchain.text_splitter import RecursiveCharacterTextSplitter

st.set_page_config(page_title="åŠ¨æ‰‹å­¦å¤§æ¨¡å‹åº”ç”¨å¼€å‘", page_icon="ğŸ¦œğŸ”—")

# ---------- 1. ä»é“¾æ¥è·å–æ–‡æ¡£å†…å®¹ ----------
def fetch_document_from_url(url):
    try:
        response = requests.get(url)
        response.raise_for_status()  # æ£€æŸ¥è¯·æ±‚æ˜¯å¦æˆåŠŸ
        return response.text
    except requests.RequestException as e:
        st.error(f"æ— æ³•è·å–æ–‡æ¡£å†…å®¹: {e}")
        st.stop()
        return ""

# æ–‡æ¡£çš„é“¾æ¥ï¼ˆæ›¿æ¢ä¸ºå®é™…çš„æ–‡æ¡£ URLï¼‰
DOCUMENT_URL = "https://book.yunzhan365.com/umhx/jlqb/mobile/index.html?qq_aio_chat_type=3"  # ç¤ºä¾‹ URL

def build_retriever():
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        st.error("è¯·å…ˆè®¾ç½®ç¯å¢ƒå˜é‡ OPENAI_API_KEY")
        st.stop()

    # ä»é“¾æ¥è·å–æ–‡æ¡£å†…å®¹
    raw_docs = fetch_document_from_url(DOCUMENT_URL)
    if not raw_docs:
        st.error("æ–‡æ¡£å†…å®¹ä¸ºç©º")
        st.stop()

    # åˆ‡åˆ†é•¿æ–‡æ¡£
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
    docs = text_splitter.create_documents([raw_docs])

    embeddings = OpenAIEmbeddings(openai_api_key=api_key)
    vectorstore = FAISS.from_documents(docs, embeddings)
    return vectorstore.as_retriever()

# ---------- 2. æ„å»ºé—®ç­”é“¾ ----------
def get_qa_chain():
    retriever = build_retriever()
    llm = ChatOpenAI(model_name="gpt-4o", temperature=0, openai_api_key=os.getenv("OPENAI_API_KEY"))

    system = (
        "ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„ AI åŠ©æ‰‹ã€‚\n"
        "è¯·ä½¿ç”¨ä¸‹é¢çš„ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ï¼Œå¦‚æœä¸çŸ¥é“å°±è¯´â€œæˆ‘ä¸çŸ¥é“â€ã€‚\n\n"
        "{context}"
    )
    prompt = ChatPromptTemplate.from_messages([
        ("system", system),
        ("human", "{question}")
    ])
    chain = (
        {"context": retriever | (lambda docs: "\n\n".join(d.page_content for d in docs)),
         "question": RunnablePassthrough()}
        | prompt
        | llm
        | StrOutputParser()
    )
    return chain

# ---------- 3. Streamlit ä¸»ç•Œé¢ ----------
def main():
    st.markdown("### ğŸ¦œğŸ”— åŠ¨æ‰‹å­¦å¤§æ¨¡å‹åº”ç”¨å¼€å‘")

    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "chain" not in st.session_state:
        st.session_state.chain = get_qa_chain()

    msgs = st.container(height=550)
    for role, text in st.session_state.messages:
        msgs.chat_message(role).write(text)

    if prompt := st.chat_input("è¯·è¾“å…¥ä½ çš„é—®é¢˜"):
        st.session_state.messages.append(("user", prompt))
        msgs.chat_message("user").write(prompt)

        with msgs.chat_message("assistant"):
            response = st.write_stream(st.session_state.chain.stream(prompt))
        st.session_state.messages.append(("assistant", response))

if __name__ == "__main__":
    main()
